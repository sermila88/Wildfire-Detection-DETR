#!/bin/bash
#SBATCH --job-name=rf_detr_hyperparameter_tuning
#SBATCH --output=outputs/hyperparameter_tuning_v2/logs/rf_detr_hyperparameter_tuning_%j.out
#SBATCH --error=outputs/hyperparameter_tuning_v2/logs/rf_detr_hyperparameter_tuning_%j.err
#SBATCH --gres=gpu:1
#SBATCH --partition=gpgpu,a16gpu,gpgpuB
#SBATCH --mem=40G
#SBATCH --time=96:00:00
#SBATCH --cpus-per-task=8

echo "ğŸ” RF-DETR Hyperparameter Tuning"
echo "ğŸ• Job started at: $(date)"
echo "ğŸ–¥ï¸  Running on node: $(hostname)"

# Create logs directory for this experiment
mkdir -p outputs/hyperparameter_tuning_v2/logs

echo "ğŸ”§ GPU info:"
nvidia-smi

source /vol/bitbucket/${USER}/rf-detr-wildfire/.venv/bin/activate
source /vol/cuda/12.0.0/setup.sh
/usr/bin/nvidia-smi

# Change to project directory  
cd /vol/bitbucket/si324/rf-detr-wildfire

# Create outputs directory
mkdir -p outputs/hyperparameter_tuning_v2

echo ""
echo "ğŸ¯ RF-DETR Optimization Configuration:"
echo "   ğŸ“Š Trials: 12 systematic trials with TPE sampler"
echo "   ğŸ”§ Parameters: lr (1e-5 to 1e-3), lr_encoder, batch_size, epochs (25-100), weight_decay, resolution"
echo "   ğŸ“ Resolution range: 896-1232px (optimized for tiny smoke detection)"
echo "   ğŸ“¦ Effective batch size: 16 (adaptive gradient accumulation)"
echo "   âš¡ Early stopping: Enabled (using EMA for decisions)"
echo "   ğŸ“ˆ EMA weights: Enabled for better model stability"
echo "   ğŸ“Š Evaluation: Binary smoke presence accuracy on validation set"
echo "   ğŸš€ Logging: All checkpoints, metrics, plots, optimizer states saved"
echo "   ğŸ’¾ Storage: ALL trials preserved with complete resumability data"
echo "   ğŸ”„ Backups: Study database backed up every 3 trials"
echo "   â±ï¸  Expected duration: 20-80 hours (comprehensive logging + early stopping)"
echo "   ğŸ›¡ï¸  Resumability: Complete state preservation for 4-day limit recovery"

echo ""
echo "ğŸš€ Starting RF-DETR hyperparameter optimization..."

# Run RF-DETR hyperparameter optimization
python train/rf_detr_hyperparameter_tuning.py

echo ""
echo "âœ… RF-DETR hyperparameter optimization completed at: $(date)"
echo "ğŸ“ Results location:"
echo "   ğŸ“Š Results: outputs/hyperparameter_tuning_v2/final_results.json"
echo "   ğŸ“‚ Individual trials: outputs/hyperparameter_tuning_v2/trial_*/"
echo "   ğŸ’¾ Optuna database: outputs/hyperparameter_tuning_v2/study.db"
echo "   ğŸ”„ Database backups: outputs/hyperparameter_tuning_v2/backups/"
echo "   ğŸ“ˆ Per-trial data: checkpoints/, plots/, metrics/, optimizer_states/, logs/"
echo ""
echo "ğŸ¯ Check the comprehensive results file for optimal hyperparameters!"
echo "ğŸš€ Use the recommended parameters to train your production model."
echo "ğŸ›¡ï¸  All data preserved for analysis and potential resumption!" 